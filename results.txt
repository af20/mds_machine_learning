RISULTATI - DATASET 19158 RIGHE
I risultati di seguito sono stati ottenuti analizzando tutti i campioni (19158)

  RIASSUNTO
    PERCEPTRON:
      Accuracy 0.65 / 0.7
      Basso Overfitting (stabilità Train-Test su Accuracy e Precision)
    LOG.REGR
      Accuracy 0.75
      Basso Overfitting (stabilità Train-Test su tutte le 4 metriche)
    SVM LINEAR
      Accuracy 0.75
      Basso Overfitting (stabilità Train-Test su tutte le 4 metriche)
      Precision più alta di LOG.REGR., ma Recall e F1 score più bassi
    SVM NON-LINEAR
      Accuracy 0.75
      Alto Overfitting: nel train si arriva anche a 0.9/1 di accuracy, ma nel validation le performance non sono migliori di quelle di altri modelli
    TREE
      Accuracy 0.77
      Basso Overfitting (stabilità Train-Test su tutte le 4 metriche)
      Leggermente migliore del Log.Regr. su tutte le metriche
    RANDOM FOREST
      Accuracy 0.77
      Basso Overfitting (stabilità Train-Test su tutte le 4 metriche)
      Migliore del Tree su Precision, ma peggiore in Recall
      Extra Trees e ADA Boosting: risultati peggiori rispetto a Random Forest



  Perceptron (Train)  |  accuracy: 0.66      precision: 0.34     recall: 0.4     f1_score: 0.37
  Perceptron (Test)   |  accuracy: 0.71      precision: 0.36     recall: 0.23     f1_score: 0.28

  Log.Reg. (Train)  |  accuracy: 0.75      precision: 0.5     recall: 0.57     f1_score: 0.53
  Log.Reg. (Test)   |  accuracy: 0.75      precision: 0.5     recall: 0.47     f1_score: 0.48

  SVM linear (Train)  |  accuracy: 0.77      precision: 0.59     recall: 0.24     f1_score: 0.34
  SVM linear (test)   |  accuracy: 0.76      precision: 0.55     recall: 0.22     f1_score: 0.32


  SVM non-linear(poly) {'degree': 5, 'coef0': 1} (Train)  |  accuracy: 0.86      precision: 0.8     recall: 0.57     f1_score: 0.66
  SVM non-linear(poly){'degree': 5, 'coef0': 1} (test)   |  accuracy: 0.74      precision: 0.46     recall: 0.34     f1_score: 0.39

  SVM non-linear(rbf) {'gamma': 5, 'C': 1} (Train)  |  accuracy: 0.9      precision: 0.93     recall: 0.64     f1_score: 0.76
  SVM non-linear(rbf){'gamma': 5, 'C': 1} (test)   |  accuracy: 0.75      precision: 0.47     recall: 0.13     f1_score: 0.2

  SVM non-linear(rbf) {'gamma': 0.1, 'C': 0.1} (Train)  |  accuracy: 0.75      precision: 0.0     recall: 0.0     f1_score: 0.0
  SVM non-linear(rbf){'gamma': 0.1, 'C': 0.1} (test)   |  accuracy: 0.75      precision: 0.0     recall: 0.0     f1_score: 0.0

  SVM non-linear(rbf) {'gamma': 10, 'C': 0.1} (Train)  |  accuracy: 0.75      precision: 0.0     recall: 0.0     f1_score: 0.0
  SVM non-linear(rbf){'gamma': 10, 'C': 0.1} (test)   |  accuracy: 0.75      precision: 0.0     recall: 0.0     f1_score: 0.0

  SVM non-linear(rbf) {'gamma': 10, 'C': 1000} (Train)  |  accuracy: 0.99      precision: 0.99     recall: 0.98     f1_score: 0.99
  SVM non-linear(rbf){'gamma': 10, 'C': 1000} (test)   |  accuracy: 0.71      precision: 0.34     recall: 0.18     f1_score: 0.24

  SVM non-linear(rbf) {'gamma': 10, 'C': 10} (Train)  |  accuracy: 0.97      precision: 0.97     recall: 0.92     f1_score: 0.94
  SVM non-linear(rbf){'gamma': 10, 'C': 10} (test)   |  accuracy: 0.72      precision: 0.37     recall: 0.18     f1_score: 0.25

  SVM non-linear(rbf) {'gamma': 10, 'C': 1} (Train)  |  accuracy: 0.92      precision: 0.96     recall: 0.72     f1_score: 0.83
  SVM non-linear(rbf){'gamma': 10, 'C': 1} (test)   |  accuracy: 0.75      precision: 0.45     recall: 0.1     f1_score: 0.16


  Tree (Train)  |  accuracy: 0.78      precision: 0.6     recall: 0.42     f1_score: 0.49
  Tree (test)   |  accuracy: 0.77      precision: 0.56     recall: 0.43     f1_score: 0.48

  Random Forest (Train)  |  accuracy: 0.78      precision: 0.68     recall: 0.25     f1_score: 0.37
  Random Forest (test)   |  accuracy: 0.77      precision: 0.63     recall: 0.23     f1_score: 0.34

  Extra Trees (Train)  |  accuracy: 0.76      precision: 0.79     recall: 0.05     f1_score: 0.1
  Extra Trees (test)   |  accuracy: 0.75      precision: 0.58     recall: 0.04     f1_score: 0.07

  ADA Boosting (Train)  |  accuracy: 0.76      precision: 0.77     recall: 0.04     f1_score: 0.07
  ADA Boosting (test)   |  accuracy: 0.76      precision: 0.73     recall: 0.04     f1_score: 0.07



----------------------------------------------------------------------------------------------
RISULTATI - DATASET 500 RIGHE
  Perceptron (Train)  |  accuracy: 0.63      precision: 0.31     recall: 0.42     f1_score: 0.36
  Perceptron (Test)   |  accuracy: 0.56      precision: 0.41     recall: 0.53     f1_score: 0.46

  Log.Reg. (Train)  |  accuracy: 0.76      precision: 0.5     recall: 0.04     f1_score: 0.08
  Log.Reg. (Test)   |  accuracy: 0.64      precision: 0.5     recall: 0.53     f1_score: 0.51

  SVM linear (Train)  |  accuracy: 0.78      precision: 0.64     recall: 0.19     f1_score: 0.29
  SVM linear (test)   |  accuracy: 0.66      precision: 1.0     recall: 0.06     f1_score: 0.11

  SVM non-linear(poly) {'degree': 5, 'coef0': 10} (Train)  |  accuracy: 1.0      precision: 1.0     recall: 0.99     f1_score: 0.99
  SVM non-linear(poly){'degree': 5, 'coef0': 10} (test)   |  accuracy: 0.64      precision: 0.5     recall: 0.31     f1_score: 0.38

  SVM non-linear(rbf) {'gamma': 10, 'C': 1} (Train)  |  accuracy: 0.99      precision: 1.0     recall: 0.95     f1_score: 0.97
  SVM non-linear(rbf){'gamma': 10, 'C': 1} (test)   |  accuracy: 0.63      precision: 0.0     recall: 0.0     f1_score: 0.0

  Tree (Train)  |  accuracy: 0.77      precision: 0.52     recall: 0.45     f1_score: 0.49
  Tree (test)   |  accuracy: 0.74      precision: 0.73     recall: 0.44     f1_score: 0.55

  Random Forest (Train)  |  accuracy: 0.94      precision: 0.97     recall: 0.79     f1_score: 0.88
  Random Forest (test)   |  accuracy: 0.78      precision: 0.6     recall: 0.16     f1_score: 0.25

  Extra Trees (Train)  |  accuracy: 0.9      precision: 0.97     recall: 0.62     f1_score: 0.75
  Extra Trees (test)   |  accuracy: 0.78      precision: 0.6     recall: 0.16     f1_score: 0.25

  ADA Boosting (Train)  |  accuracy: 0.9      precision: 0.97     recall: 0.62     f1_score: 0.75
  ADA Boosting (test)   |  accuracy: 0.78      precision: 0.6     recall: 0.16     f1_score: 0.25
